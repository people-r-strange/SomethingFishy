---
title: "DC_1"
output: html_document
author: Lauren Low
---

```{r loading packages}
library(tidyverse)
library(dplyr)
library(readxl)
library(stringr)
library(readr)
library(data.table)
library(vroom)
library(readtext)
library(textrank)
library(tidytext)
library(janeaustenr)
library(tidyr)
library(igraph)
library(ggraph)
library(ggplot2)
```

```{r loading files and joinging dataframes}

conference <- read_excel("/Users/llow/Desktop/DC1-data/City Hall Phone Log/Conference Room Phone Log.xls", sheet = "Sheet1")
voter <- read_excel("/Users/llow/Desktop/DC1-data/Voter Registry/Voter Registry.xls", sheet = "Sheet1")
conference
voter
```

```{r manually reading in text as a vector}
# it would take a lot of time to manually coy and paste each article into r
text <- c("
Alderwood to probe voting machines Story by: Ellie Olmsen Date Published to Web: 11/16/2004 Republicans in Alderwood joined Democrats yesterday in criticizing the performance of the city's costly new high-tech voting system, saying that it may have disenfranchised voters in the Nov. 4 election. The Republican commission scolded the city board of elections for minimizing problems with the touch-screen machines that the city purchased this year for $1.5 million and asked Mayor Rex Luthor to investigate what went wrong before the machines are pressed into service again. Alderwood's touch-screen voting machines, which resemble laptop computers without keyboards, were supposed to simplify voting and tabulating results. But in a debut that mirrored many of the problems experienced last year in areas across the country, some voters found the machines confusing, and the reporting of vote tallies was delayed almost a day. Luthor responded that he would try to address the board's concerns. He said he has called for a public meeting of the three-member board of elections to go over the requests at 5 p.m. today. I pledge that I will answer every question as soon as I possibly can in the proper fashion, he said."
)
```

```{r finding most common word in text}
# put text in a df
text_df <- data_frame(long_string = text) 

# makes each word its own column
word_col <- text_df %>% 
   unnest_tokens(output = word, input = long_string) 
 
# removes stop words like "the", "and", "before", "after", "such", "as", etc.
no_stops  <- word_col  %>%
  anti_join(stop_words)

# finds most common word and counts
common <- no_stops %>%
  count(word, sort = TRUE)
common
```

```{r reading in all of the text files}
# lets see if we can read in all the files in to News Articles folder so we don't have to copy and paste a bunch
dir <- "/Users/llow/Desktop/DC1-data/News Articles"
article = readtext(paste0(dir, "/*.txt"))
article
```

```{r analyszing all articles for most common words}
# put text in a df
text_df <- data_frame(long_string = article) 

# makes each word its own column
word_col <- text_df %>% 
   unnest_tokens(output = word, input = long_string) 
 
# removes stop words like "the", "and", "before", "after", "such", "as", etc.
no_stops  <- word_col  %>%
  anti_join(stop_words)

# finds most common word and counts
common <- no_stops %>%
  count(word, sort = TRUE) %>%
  slice(1:25) %>%
  filter(rank(desc(n))>0)
common
```

```{r plotting most common words}
plot <-ggplot(data = common, aes(x = reorder(word, n), y = n)) +
  geom_bar(stat = "identity") + 
  coord_flip() +
  xlab("Common Words") + 
  ylab("Number of Occurances in all Articles")
plot
```


figured out how to do bits of text analysis here: https://steemit.com/programming/@dkmathstats/finding-the-most-frequent-words-in-text-with-r
https://stackoverflow.com/questions/23413331/how-to-remove-last-n-characters-from-every-element-in-the-r-vector


```{r fidnign all bigrams}
bigrams <- article %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigrams
```

```{r counting number of each bigram}
bis <- bigrams %>%
  count(bigram, sort = TRUE)
bis
```

```{r separating bigrams into two columns}
bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
bigrams_separated
```

```{r separating bigrams into two columns and filtering out stop words}
# separates bigrams
bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
bigrams_separated

# filters out stop words in bigrams
bigrams_filtered <- bigrams_separated %>%
   filter(!word1 %in% stop_words$word) %>%
   filter(!word2 %in% stop_words$word)
bigrams_filtered

# new bigram counts:
bigram_counts <- bigrams_filtered %>%
  count(word1, word2, sort = TRUE)
bigram_counts
```

```{r looks at bigrams}
bigrams_united1 <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")
  # count(bigram, sort = TRUE) %>%
  # slice(1:40) 
#  filter(rank(desc(n))>0)
bigrams_united1
```

```{r looks at bigrams}
bigrams_united2 <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ") %>%
  count(bigram, sort = TRUE) %>%
  slice(1:30) 
bigrams_united2
```

```{r orders most common to least common bigrams}
plot2 <-ggplot(data = bigrams_united2, aes(x = reorder(bigram, n), y = n)) +
  geom_bar(stat = "identity") + 
  coord_flip() +
  xlab("Common Bigrams") + 
  ylab("Number of Occurances in all Articles")
plot2
```

```{r more bigram analysis, looking at term frequency and inverse document frequency}
bigram_tf_idf <- bigrams_united %>%
  count(doc_id, bigram) %>%
  bind_tf_idf(bigram, doc_id, n) %>%
  arrange(desc(tf_idf))
bigram_tf_idf
```

```{r data table to graph words}
# filter for only relatively common combinations
bigram_graph <- bigram_counts %>%
  group_by(word1) %>%
  filter(n > 50) %>%
  graph_from_data_frame()
bigram_graph
```

```{r graph of words}
grapho <- ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
grapho
```

```{r}
library(plotly)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void() 
```


